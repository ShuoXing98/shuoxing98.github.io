---
title:          "OpenEMMA: Open-Source Multimodal Model for End-to-End Autonomous Driving"
date:           2025-01-03 23:01:00 +0800
selected:       true
pub:            "3rd WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       '<a href="https://github.com/taco-group/OpenEMMA" target="_blank"><img src="https://img.shields.io/github/stars/taco-group/OpenEMMA"></a>'
pub_date:       "2025"

abstract: >-
  Drawing inspiration from recent advancements in inference computing, we propose OpenEMMA, an open-source end-to-end framework based on MLLMs. By incorporating the Chain-of-Thought reasoning process, OpenEMMA achieves significant improvements compared to the baseline when leveraging a diverse range of MLLMs. Furthermore, OpenEMMA demonstrates effectiveness, generalizability, and robustness across a variety of challenging driving scenarios, offering a more efficient and effective approach to autonomous driving.
cover:          /assets/images/covers/openemma-pipeline.png
authors:
  - Shuo Xing
  - Chengyuan Qian
  - Yuping Wang
  - Hongyuan Hua
  - Kexin Tian
  - Yang Zhou
  - Zhengzhong Tu
links:
  Paper: https://arxiv.org/abs/2412.15208
  Code: https://github.com/taco-group/OpenEMMA
---
